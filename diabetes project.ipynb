{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2075c69-cbf4-4928-adf6-71948751542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, cross_val_predict\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f93825-77b8-43b1-b096-5d1d8ce879d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Step 1: Data Pre-processing\")\n",
    "df = pd.read_csv(\"diabetes project.csv\") \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fd3801-e908-4b67-9d60-1f81781bbb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the information of the data\n",
    "#remove outlier\n",
    "#impute missing value with median\n",
    "#check the number of missing value \n",
    "#normalize the data with zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "106fd04c-ee84-425d-8c4d-e897003965e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pregnancies  Glucose  BloodPressure  SkinThickness   BMI  \\\n",
      "0            6    148.0             72           35.0  33.6   \n",
      "1            1     85.0             66           29.0  26.6   \n",
      "2            8    117.0             64          -35.0  23.3   \n",
      "3            1     89.0             66           23.0  28.1   \n",
      "4            0    137.0             40           35.0  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  \n",
      "0                     0.627   50  \n",
      "1                     0.351   31  \n",
      "2                     0.672   32  \n",
      "3                     0.167   21  \n",
      "4                     0.355   33  \n",
      "Pregnancies                 0\n",
      "Glucose                     0\n",
      "BloodPressure               0\n",
      "SkinThickness               0\n",
      "BMI                         0\n",
      "DiabetesPedigreeFunction    0\n",
      "Age                         0\n",
      "dtype: int64\n",
      "median is:\n",
      "Pregnancies                   3.000\n",
      "Glucose                     117.000\n",
      "BloodPressure                72.000\n",
      "SkinThickness                29.000\n",
      "BMI                          32.250\n",
      "DiabetesPedigreeFunction      0.355\n",
      "Age                          29.000\n",
      "dtype: float64\n",
      "Pregnancies                 0\n",
      "Glucose                     0\n",
      "BloodPressure               0\n",
      "SkinThickness               0\n",
      "BMI                         0\n",
      "DiabetesPedigreeFunction    0\n",
      "Age                         0\n",
      "dtype: int64\n",
      "     Pregnancies   Glucose  BloodPressure  SkinThickness       BMI  \\\n",
      "0       0.679620  1.143472      -0.031011       0.867717  0.212745   \n",
      "1      -0.857915 -1.337355      -0.536147       0.052285 -0.878140   \n",
      "2       1.294634 -0.077252      -0.704526       0.052285 -1.392414   \n",
      "3      -0.857915 -1.179842      -0.536147      -0.763146 -0.644379   \n",
      "4      -1.165422  0.710312      -2.725069       0.867717  1.693231   \n",
      "..           ...       ...            ...            ...       ...   \n",
      "728     1.909648 -0.707304       0.305746       0.052285  0.103656   \n",
      "729    -0.550408  0.119639      -0.199390      -0.219525  0.711435   \n",
      "730     0.372113  0.080261      -0.031011      -0.763146 -0.940476   \n",
      "731    -0.857915  0.277152      -1.041283       0.052285 -0.332698   \n",
      "732    -0.857915 -1.022329      -0.199390       0.324096 -0.285945   \n",
      "\n",
      "     DiabetesPedigreeFunction       Age  \n",
      "0                    1.025977  1.428456  \n",
      "1                   -0.261365 -0.198076  \n",
      "2                    1.235870 -0.112469  \n",
      "3                   -1.119594 -1.054145  \n",
      "4                   -0.242708 -0.026862  \n",
      "..                        ...       ...  \n",
      "728                 -1.100937  2.541346  \n",
      "729                 -0.312673 -0.540503  \n",
      "730                 -0.755780 -0.283682  \n",
      "731                 -0.270694  1.171635  \n",
      "732                 -0.429280 -0.882931  \n",
      "\n",
      "[733 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head(5))\n",
    "print(df.isnull().sum())\n",
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower = Q1 - 1.5 * IQR\n",
    "upper = Q3 + 1.5 * IQR\n",
    "df_no_outlier = (df >= lower) & (df <= upper)\n",
    "outlier_count = (~df_no_outlier).sum().sum()\n",
    "df[~df_no_outlier] = np.nan\n",
    "# Impute missing values\n",
    "median_values = df.median()\n",
    "df = df.fillna(median_values)\n",
    "print(\"median is:\")\n",
    "print(median_values)\n",
    "print(df_no_outlier.isnull().sum())\n",
    "\n",
    "#normalize data\n",
    "scaler = StandardScaler()\n",
    "df_normalized = pd.DataFrame(\n",
    "    scaler.fit_transform(df),\n",
    "    columns=df.columns\n",
    ")\n",
    "print(df_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4856fa4-4cc8-4e35-a36b-a07443b374d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use K-means clustering on three features of Glucose, BMI and Age to cluster data into two clusters.\n",
    "#Assign ‘Diabetes’ name to the cluster with higher average Glucose and ‘No Diabetes’ to the other cluster.\n",
    "#Add a new column (Outcome) to the dataset containing 1 for ‘Diabetes’ and 0 for ‘No Diabetes’. Use these values as labels for classification (step 4).\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36a47401-2367-4539-89d3-7e37df45c644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Glucose       BMI       Age  Cluster_label\n",
      "0  1.143472  0.212745  1.428456              0\n",
      "1 -1.337355 -0.878140 -0.198076              1\n",
      "2 -0.077252 -1.392414 -0.112469              1\n",
      "3 -1.179842 -0.644379 -1.054145              1\n",
      "4  0.710312  1.693231 -0.026862              0\n",
      "5 -0.077252 -1.033981 -0.283682              1\n",
      "6 -0.077252 -0.192441 -0.626110              1\n",
      "7 -0.077252 -0.270361  1.685277              0\n",
      "8  0.237773  0.002360  1.770884              0\n",
      "9 -0.352900  0.836108 -0.283682              1\n",
      "Labels generated: 0=444, 1=289\n",
      "0    0.721758\n",
      "1   -0.469793\n",
      "Name: Glucose, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Unsupervised learning for generating labels\n",
    "cluster_df = df_normalized[['Glucose', 'BMI', 'Age']].copy()\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "labels = kmeans.fit_predict(cluster_df)\n",
    "cluster_df['Cluster_label'] = labels\n",
    "print(cluster_df.head(10))\n",
    "# Assign diabetes to cluster with higher glucose\n",
    "cluster_glu_means = cluster_df.groupby(labels)[\"Glucose\"].mean()\n",
    "diabetes_cluster = cluster_glu_means.idxmax()\n",
    "df_normalized[\"Outcome\"] = (labels == diabetes_cluster).astype(int)\n",
    "print(f\"Labels generated: 0={np.sum(df_normalized['Outcome']==0)}, 1={np.sum(df_normalized['Outcome']==1)}\")\n",
    "print(cluster_glu_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "132b591c-b9b4-43aa-82eb-b30c3b4aca81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Unsupervised Learning for Label Generation\n",
      "Labels generated: 0=444, 1=289\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 2: Unsupervised Learning for Label Generation\")\n",
    "\n",
    "\n",
    "# K-means clustering on Glucose, BMI, and Age\n",
    "cluster_df = df_normalized[['Glucose', 'BMI', 'Age']]\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "labels = kmeans.fit_predict(cluster_df)\n",
    "\n",
    "# Assign diabetes to cluster with higher glucose\n",
    "cluster_glu_means = cluster_df.groupby(labels)[\"Glucose\"].mean()\n",
    "diabetes_cluster = cluster_glu_means.idxmax()\n",
    "df_normalized[\"Outcome\"] = (labels == diabetes_cluster).astype(int)\n",
    "\n",
    "print(f\"Labels generated: 0={np.sum(df_normalized['Outcome']==0)}, 1={np.sum(df_normalized['Outcome']==1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704e2555-467c-461b-ab36-59647abef01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into test and training sets (consider 20% for test).\n",
    "Use PCA on the training data to create 3 new #components from existing features (all columns except outcome).\n",
    "Transfer training and test data to the new dimensions (PCs).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a970f327-a84d-4ce8-9fc1-3ff8c08e801d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Feature Extraction\n",
      "Training set size: (586, 7)\n",
      "Test set size: (147, 7)\n",
      "\n",
      "PCA training data shape: (586, 3)\n",
      "PCA test data shape: (147, 3)\n",
      "Explained variance ratio: [0.30467407 0.19959433 0.13742567]\n",
      "Total variance explained: 0.6417\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 3: Feature Extraction\")\n",
    "\n",
    "# Split data into training and test sets\n",
    "X = df_normalized.drop('Outcome', axis=1)\n",
    "y = df_normalized['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}\")\n",
    "\n",
    "# Apply PCA to create 3 principal components\n",
    "pca = PCA(n_components=3)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(f\"\\nPCA training data shape: {X_train_pca.shape}\")\n",
    "print(f\"PCA test data shape: {X_test_pca.shape}\")\n",
    "print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Total variance explained: {pca.explained_variance_ratio_.sum():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa669664-8d09-4373-b548-894e452b48cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D PCA Visualization\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Blue: No diabetes\n",
    "ax.scatter(X_train_pca[y_train==0, 0], \n",
    "           X_train_pca[y_train==0, 1], \n",
    "           X_train_pca[y_train==0, 2],\n",
    "           c='blue', label='No Diabetes (0)', alpha=0.6)\n",
    "\n",
    "# Red: Diabetes\n",
    "ax.scatter(X_train_pca[y_train==1, 0], \n",
    "           X_train_pca[y_train==1, 1], \n",
    "           X_train_pca[y_train==1, 2],\n",
    "           c='red', label='Diabetes (1)', alpha=0.6)\n",
    "\n",
    "# Labels and title\n",
    "ax.set_xlabel('PC 1')\n",
    "ax.set_ylabel('PC 2')\n",
    "ax.set_zlabel('PC 3')\n",
    "ax.set_title('3D PCA Visualization of Training Data')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b42d36a8-669b-455c-b48e-f16506dc0585",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define three classification models as base classifiers consisting of Naïve Bayes, Neural Network, and KNN.\n",
    "#Define a decision tree as the meta learner.\n",
    "#Train decision tree (meta learner) on outputs of three base classifiers using 5-fold cross validation.\n",
    "#Find hyperparameters for all these models which provide the best accuracy rate.\n",
    "#Report accuracy of the model on the test data.\n",
    "#base learner:knn,nb mlp stacking \n",
    "#then meta learner: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719de45d-c783-451d-b94d-b9a6265cabdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Step 4: Classification using a Super Learner\")\n",
    "\n",
    "# Define base classifiers\n",
    "nb = GaussianNB()\n",
    "knn = KNeighborsClassifier()\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "\n",
    "print(\"Generating meta-features using 5-fold cross-validation...\")\n",
    "\n",
    "# Generate meta-features using cross-validation\n",
    "p1_train = cross_val_predict(nb, X_train_pca, y_train, cv=5)\n",
    "p2_train = cross_val_predict(knn, X_train_pca, y_train, cv=5)\n",
    "p3_train = cross_val_predict(mlp, X_train_pca, y_train, cv=5)\n",
    "\n",
    "# Stack predictions to create meta-features\n",
    "X_meta_train = np.column_stack((p1_train, p2_train, p3_train))\n",
    "\n",
    "print(f\"Meta-features shape: {X_meta_train.shape}\")\n",
    "print(\"✓ Meta-features generated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb72ece-fc27-408f-97dc-295fbbcfdf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train base models on full training set\n",
    "print(\"\\nTraining base models on full training set...\")\n",
    "\n",
    "nb.fit(X_train_pca, y_train)\n",
    "knn.fit(X_train_pca, y_train)\n",
    "mlp.fit(X_train_pca, y_train)\n",
    "\n",
    "print(\"✓ Base models trained!\")\n",
    "\n",
    "# Generate predictions on test set\n",
    "print(\"\\nGenerating predictions on test set...\")\n",
    "p1_test = nb.predict(X_test_pca)\n",
    "p2_test = knn.predict(X_test_pca)\n",
    "p3_test = mlp.predict(X_test_pca)\n",
    "\n",
    "# Create meta-features for test set\n",
    "X_meta_test = np.column_stack((p1_test, p2_test, p3_test))\n",
    "\n",
    "print(f\"Test meta-features shape: {X_meta_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bc3976-6224-4211-b0ba-09169748c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune meta-learner (Decision Tree)\n",
    "print(\"Tuning Meta-Learner (Decision Tree)\")\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [3, 5, 7, 10, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "print(f\"Testing {len(param_grid['criterion']) * len(param_grid['max_depth']) * len(param_grid['min_samples_split'])} parameter combinations...\")\n",
    "print(\"This will perform 5-fold cross-validation for each combination...\\n\")\n",
    "\n",
    "# Grid search with cross-validation\n",
    "grid_search = GridSearchCV(dt, param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "grid_search.fit(X_meta_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_meta_test)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Best Parameters Found:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
    "print(\"\\n✓ Meta-learner tuned!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "556c9ef5-89c0-474c-9ba6-7a93d6b83572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FINAL RESULTS\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Super learner accuracy\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m super_learner_acc = accuracy_score(\u001b[43my_test\u001b[49m, y_pred)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mSuper Learner Test Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuper_learner_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Individual model accuracies\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"FINAL RESULTS\")\n",
    "\n",
    "\n",
    "# Super learner accuracy\n",
    "super_learner_acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nSuper Learner Test Accuracy: {super_learner_acc:.4f}\")\n",
    "\n",
    "# Individual model accuracies\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Individual Base Model Performance:\")\n",
    "print(\"-\" * 70)\n",
    "nb_acc = accuracy_score(y_test, p1_test)\n",
    "knn_acc = accuracy_score(y_test, p2_test)\n",
    "mlp_acc = accuracy_score(y_test, p3_test)\n",
    "\n",
    "print(f\"  Naive Bayes:   {nb_acc:.4f}\")\n",
    "print(f\"  KNN:           {knn_acc:.4f}\")\n",
    "print(f\"  MLP:           {mlp_acc:.4f}\")\n",
    "print(f\"  Super Learner: {super_learner_acc:.4f}\")\n",
    "\n",
    "# Improvement\n",
    "best_base = max(nb_acc, knn_acc, mlp_acc)\n",
    "improvement = super_learner_acc - best_base\n",
    "print(f\"\\nImprovement over best base model: {improvement:.4f} ({improvement*100:.2f}%)\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Detailed Classification Report\")\n",
    "print(\"=\" * 70)\n",
    "print(classification_report(y_test, y_pred, \n",
    "                          target_names=['No Diabetes (0)', 'Diabetes (1)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6229ba-767f-4739-af4e-e9909cd0893f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
